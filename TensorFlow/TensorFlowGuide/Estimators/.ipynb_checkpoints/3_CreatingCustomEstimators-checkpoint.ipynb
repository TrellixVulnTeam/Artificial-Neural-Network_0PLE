{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import iris_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/custom_estimators\n",
    "https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0            6.4         2.8          5.6         2.2\n",
      "1            5.0         2.3          3.3         1.0\n",
      "2            4.9         2.5          4.5         1.7\n",
      "3            4.9         3.1          1.5         0.1\n",
      "4            5.7         3.8          1.7         0.3\n",
      "5            4.4         3.2          1.3         0.2\n",
      "6            5.4         3.4          1.5         0.4\n",
      "7            6.9         3.1          5.1         2.3\n",
      "8            6.7         3.1          4.4         1.4\n",
      "9            5.1         3.7          1.5         0.4\n",
      "10           5.2         2.7          3.9         1.4\n",
      "11           6.9         3.1          4.9         1.5\n",
      "12           5.8         4.0          1.2         0.2\n",
      "13           5.4         3.9          1.7         0.4\n",
      "14           7.7         3.8          6.7         2.2\n",
      "15           6.3         3.3          4.7         1.6\n",
      "16           6.8         3.2          5.9         2.3\n",
      "17           7.6         3.0          6.6         2.1\n",
      "18           6.4         3.2          5.3         2.3\n",
      "19           5.7         4.4          1.5         0.4\n",
      "20           6.7         3.3          5.7         2.1\n",
      "21           6.4         2.8          5.6         2.1\n",
      "22           5.4         3.9          1.3         0.4\n",
      "23           6.1         2.6          5.6         1.4\n",
      "24           7.2         3.0          5.8         1.6\n",
      "25           5.2         3.5          1.5         0.2\n",
      "26           5.8         2.6          4.0         1.2\n",
      "27           5.9         3.0          5.1         1.8\n",
      "28           5.4         3.0          4.5         1.5\n",
      "29           6.7         3.0          5.0         1.7\n",
      "..           ...         ...          ...         ...\n",
      "90           6.5         3.0          5.2         2.0\n",
      "91           6.1         2.8          4.7         1.2\n",
      "92           5.1         3.5          1.4         0.3\n",
      "93           4.6         3.1          1.5         0.2\n",
      "94           6.5         3.0          5.8         2.2\n",
      "95           4.6         3.4          1.4         0.3\n",
      "96           4.6         3.2          1.4         0.2\n",
      "97           7.7         2.8          6.7         2.0\n",
      "98           5.9         3.2          4.8         1.8\n",
      "99           5.1         3.8          1.6         0.2\n",
      "100          4.9         3.0          1.4         0.2\n",
      "101          4.9         2.4          3.3         1.0\n",
      "102          4.5         2.3          1.3         0.3\n",
      "103          5.8         2.7          4.1         1.0\n",
      "104          5.0         3.4          1.6         0.4\n",
      "105          5.2         3.4          1.4         0.2\n",
      "106          5.3         3.7          1.5         0.2\n",
      "107          5.0         3.6          1.4         0.2\n",
      "108          5.6         2.9          3.6         1.3\n",
      "109          4.8         3.1          1.6         0.2\n",
      "110          6.3         2.7          4.9         1.8\n",
      "111          5.7         2.8          4.1         1.3\n",
      "112          5.0         3.0          1.6         0.2\n",
      "113          6.3         3.3          6.0         2.5\n",
      "114          5.0         3.5          1.6         0.6\n",
      "115          5.5         2.6          4.4         1.2\n",
      "116          5.7         3.0          4.2         1.2\n",
      "117          4.4         2.9          1.4         0.2\n",
      "118          4.8         3.0          1.4         0.1\n",
      "119          5.5         2.4          3.7         1.0\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "(120,)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_x)\n",
    "print(train_y.shape)\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'models/iris3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A8497BECF8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
    "    # Create three fully connected layers each layer having a dropout\n",
    "    # probability of 0.1.\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "        print(net)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "    print(logits)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        'hidden_units': [10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        'n_classes': 3,\n",
    "    },\n",
    "    model_dir='models/iris3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into models/iris3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0805608, step = 0\n",
      "INFO:tensorflow:global_step/sec: 294.31\n",
      "INFO:tensorflow:loss = 0.18914571, step = 100 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.198\n",
      "INFO:tensorflow:loss = 0.09682205, step = 200 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.911\n",
      "INFO:tensorflow:loss = 0.05848893, step = 300 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.661\n",
      "INFO:tensorflow:loss = 0.081516124, step = 400 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.253\n",
      "INFO:tensorflow:loss = 0.08734969, step = 500 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.011\n",
      "INFO:tensorflow:loss = 0.065640464, step = 600 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.39\n",
      "INFO:tensorflow:loss = 0.052938547, step = 700 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.211\n",
      "INFO:tensorflow:loss = 0.061440025, step = 800 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.464\n",
      "INFO:tensorflow:loss = 0.059348326, step = 900 (0.192 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into models/iris3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05344523.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a8497bebe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(input_fn=lambda:iris_data.train_input_fn(train_x, train_y, 100), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-10-20:41:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris3\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-10-20:41:42\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, global_step = 1000, loss = 0.057531442\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, 100))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris3\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.7%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (96.5%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            labels=None,\n",
    "                                            batch_size=100))\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
