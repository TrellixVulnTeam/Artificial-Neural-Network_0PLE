{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inspired by https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py\n",
    "# https://github.com/nlintz/TensorFlow-Tutorials/blob/master/07_lstm.ipynb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorboard --logdir \"rnn_mnist_logs_2_many2many_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../Datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "#                        O * W + b -> 10 labels for each image, O[? 28], W[28 10], B[10]\n",
    "#                       ^ (O: output 28 vec from 28 vec input)\n",
    "#                       |\n",
    "#      +-+  +-+       +--+\n",
    "#      |1|->|2|-> ... |28| time_step_size = 28\n",
    "#      +-+  +-+       +--+\n",
    "#       ^    ^    ...  ^\n",
    "#       |    |         |\n",
    "# img1:[28] [28]  ... [28]\n",
    "# img2:[28] [28]  ... [28]\n",
    "# img3:[28] [28]  ... [28]\n",
    "# ...\n",
    "# img128 or img256 (batch_size or test_size 256)\n",
    "#      each input size = input_vec_size=lstm_size=28\n",
    "\n",
    "# configuration variables\n",
    "input_vec_size = lstm_size = 28\n",
    "time_step_size = 28\n",
    "\n",
    "batch_size = 128\n",
    "test_size = 256\n",
    "\n",
    "def init_weights(shape, name):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
    "\n",
    "def model(X, W, B, lstm_size):\n",
    "    with tf.name_scope('Model'):\n",
    "        # X, input shape: (batch_size, time_step_size, input_vec_size)\n",
    "        XT = tf.transpose(X, [1, 0, 2])  # permute time_step_size and batch_size\n",
    "        # XT shape: (time_step_size, batch_size, input_vec_size)\n",
    "\n",
    "        XR = tf.reshape(XT, [-1, lstm_size]) # each row has input for each lstm cell (lstm_size=input_vec_size)\n",
    "        # XR shape: (time_step_size * batch_size, input_vec_size)\n",
    "        \"\"\"\n",
    "        X_split will contain 28 tensors of shape 'batch_size' x 28\n",
    "        So that, 1st tensor will contain 1st row (28 pixels) of 'batch_size' images\n",
    "        2nd tensor will contain 2nd row (28 pixels) of 'batch_size' images\n",
    "        ...\n",
    "        \"\"\"\n",
    "        X_split = tf.split(XR, time_step_size, 0) # split them to time_step_size (28 arrays)\n",
    "        # Each array shape: (batch_size, input_vec_size)\n",
    "\n",
    "        # Make lstm with lstm_size (each input vector size)\n",
    "        \"\"\"\n",
    "        https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell\n",
    "        BasicLSTMCell(num_units, forget_bias=1.0, state_is_tuple=True, activation=None, reuse=None)\n",
    "        The value of \"num_units\" is it up to you, too high a value may lead to overfitting\n",
    "        or a very low value may yield extremely poor results.\n",
    "        But, the shape of \"outputs\" depends on \"num_units\"\n",
    "        So, define the shape of \"weights\" accourdingly because \"outputs[-1]\" and \"weights\" will be multiplied\n",
    "        \"\"\"\n",
    "        lstm = rnn.BasicLSTMCell(lstm_size, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "        # Get lstm cell output, time_step_size (28) arrays with lstm_size output: (batch_size, lstm_size)\n",
    "        outputs, _states = rnn.static_rnn(lstm, X_split, dtype=tf.float32)\n",
    "\n",
    "        # Linear activation\n",
    "        # Get the last output\n",
    "#         print(\"X_split: \", X_split)\n",
    "#         print(\"outputs: \", outputs)\n",
    "        logits1 = tf.matmul(outputs[0], W) + B\n",
    "        logits2 = tf.matmul(outputs[6], W) + B\n",
    "        logits3 = tf.matmul(outputs[13], W) + B\n",
    "        logits4 = tf.matmul(outputs[20], W) + B\n",
    "        logits5 = tf.matmul(outputs[27], W) + B\n",
    "    return logits1, logits2, logits3, logits4, logits5\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../../../Datasets/MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "# print(len(trX))\n",
    "# print(len(trX[0]))\n",
    "trX = trX.reshape(-1, 28, 28) # (55000, 28, 28)\n",
    "# print(len(trX))\n",
    "# print(len(trX[0]))\n",
    "# print(len(trX[0][0]))\n",
    "teX = teX.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "XT = tf.transpose(trX, [1, 0, 2])\n",
    "print(XT)\n",
    "XR = tf.reshape(XT, [-1, lstm_size])\n",
    "print(XR)\n",
    "X_split = tf.split(XR, time_step_size, 0)\n",
    "print(X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ad27b8f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prints the image\n",
    "Input: image pixels in list\n",
    "\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def print_image(image, title):\n",
    "    plt.imshow(image, cmap=plt.cm.gray)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "print_image(trX[5700], \"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:  <tf.Variable 'Weights:0' shape=(28, 10) dtype=float32_ref>\n",
      "B:  <tf.Variable 'Bias:0' shape=(10,) dtype=float32_ref>\n",
      "logits1:  Tensor(\"Model/add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy5:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, 28, 28], name='InputData')\n",
    "Y = tf.placeholder(\"float\", [None, 10], name='LabelData')\n",
    "\n",
    "# get lstm_size and output 10 labels\n",
    "W = init_weights([lstm_size, 10], \"Weights\")\n",
    "B = init_weights([10], \"Bias\")\n",
    "print(\"W: \", W)\n",
    "print(\"B: \", B)\n",
    "\n",
    "tf.summary.histogram(\"weights\", W)\n",
    "tf.summary.histogram(\"biases\", B)\n",
    "\n",
    "#py_x, state_size = model(X, W, B, lstm_size)\n",
    "logits1, logits2, logits3, logits4, logits5 = model(X, W, B, lstm_size)\n",
    "\n",
    "print(\"logits1: \", logits1)\n",
    "\n",
    "with tf.name_scope('Loss_logits1'):\n",
    "    cost1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1, labels=Y))\n",
    "tf.summary.scalar(\"loss_logits1\", cost1) # Create a summary to monitor loss_op tensor\n",
    "with tf.name_scope('Loss_logits2'):\n",
    "    cost2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2, labels=Y))\n",
    "tf.summary.scalar(\"loss_logits2\", cost2) # Create a summary to monitor loss_op tensor\n",
    "with tf.name_scope('Loss_logits3'):\n",
    "    cost3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3, labels=Y))\n",
    "tf.summary.scalar(\"loss_logits3\", cost3) # Create a summary to monitor loss_op tensor\n",
    "with tf.name_scope('Loss_logits4'):\n",
    "    cost4 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits4, labels=Y))\n",
    "tf.summary.scalar(\"loss_logits4\", cost4) # Create a summary to monitor loss_op tensor\n",
    "with tf.name_scope('Loss_logits5'):\n",
    "    cost5 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits5, labels=Y))\n",
    "tf.summary.scalar(\"loss_logits5\", cost1) # Create a summary to monitor loss_op tensor\n",
    "\n",
    "train_op1 = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost1)\n",
    "train_op2 = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost2)\n",
    "train_op3 = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost3)\n",
    "train_op4 = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost4)\n",
    "train_op5 = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost5)\n",
    "\n",
    "predict_op1 = tf.argmax(logits1, 1)\n",
    "predict_op2 = tf.argmax(logits2, 1)\n",
    "predict_op3 = tf.argmax(logits3, 1)\n",
    "predict_op4 = tf.argmax(logits4, 1)\n",
    "predict_op5 = tf.argmax(logits5, 1)\n",
    "\n",
    "prediction1 = tf.nn.softmax(logits1)\n",
    "correct_pred1 = tf.equal(tf.argmax(prediction1, 1), tf.argmax(Y, 1))\n",
    "with tf.name_scope('Accuracy1'):\n",
    "    accuracy1 = tf.reduce_mean(tf.cast(correct_pred1, tf.float32))\n",
    "tf.summary.scalar(\"accuracy1\", accuracy1) # Create a summary to monitor accuracy tensor\n",
    "\n",
    "prediction2 = tf.nn.softmax(logits2)\n",
    "correct_pred2 = tf.equal(tf.argmax(prediction2, 1), tf.argmax(Y, 1))\n",
    "with tf.name_scope('Accuracy2'):\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct_pred2, tf.float32))\n",
    "tf.summary.scalar(\"accuracy2\", accuracy2) # Create a summary to monitor accuracy tensor\n",
    "\n",
    "prediction3 = tf.nn.softmax(logits3)\n",
    "correct_pred3 = tf.equal(tf.argmax(prediction3, 1), tf.argmax(Y, 1))\n",
    "with tf.name_scope('Accuracy3'):\n",
    "    accuracy3 = tf.reduce_mean(tf.cast(correct_pred3, tf.float32))\n",
    "tf.summary.scalar(\"accuracy3\", accuracy3) # Create a summary to monitor accuracy tensor\n",
    "\n",
    "prediction4 = tf.nn.softmax(logits4)\n",
    "correct_pred4 = tf.equal(tf.argmax(prediction4, 1), tf.argmax(Y, 1))\n",
    "with tf.name_scope('Accuracy4'):\n",
    "    accuracy4 = tf.reduce_mean(tf.cast(correct_pred4, tf.float32))\n",
    "tf.summary.scalar(\"accuracy4\", accuracy4) # Create a summary to monitor accuracy tensor\n",
    "\n",
    "prediction5 = tf.nn.softmax(logits5)\n",
    "correct_pred5 = tf.equal(tf.argmax(prediction5, 1), tf.argmax(Y, 1))\n",
    "with tf.name_scope('Accuracy5'):\n",
    "    accuracy5 = tf.reduce_mean(tf.cast(correct_pred5, tf.float32))\n",
    "tf.summary.scalar(\"accuracy5\", accuracy5) # Create a summary to monitor accuracy tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trX_temp, trY_temp = trX[0:batch_size], trY[0:batch_size]\n",
    "\n",
    "XT_temp = tf.transpose(trX_temp, [1, 0, 2])\n",
    "XR_temp = tf.reshape(XT_temp, [-1, lstm_size])\n",
    "X_split_temp = tf.split(XR_temp, time_step_size, 0)\n",
    "lstm_temp = rnn.BasicLSTMCell(lstm_size, forget_bias=1.0, reuse=True)\n",
    "outputs_temp, _states_temp = rnn.static_rnn(lstm_temp, X_split_temp, dtype=tf.float32)\n",
    "W_temp = init_weights([lstm_size, 10], \"Weights\")\n",
    "B_temp = init_weights([10], \"Bias\")\n",
    "py_x_temp, state_size_temp = tf.matmul(outputs_temp[-1], W_temp) + B_temp, lstm_temp.state_size\n",
    "\n",
    "print(\"py_x_temp: \", py_x_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(\"rnn_mnist_logs_2_many2many_lstm/\"):\n",
    "    shutil.rmtree(\"rnn_mnist_logs_2_many2many_lstm/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "predict_op1 0.125\n",
      "predict_op2 0.36328125\n",
      "predict_op3 0.62109375\n",
      "predict_op4 0.6171875\n",
      "predict_op5 0.59375\n",
      "\n",
      "epoch:  1\n",
      "predict_op1 0.10546875\n",
      "predict_op2 0.53515625\n",
      "predict_op3 0.8046875\n",
      "predict_op4 0.85546875\n",
      "predict_op5 0.8203125\n",
      "\n",
      "epoch:  2\n",
      "predict_op1 0.11328125\n",
      "predict_op2 0.53125\n",
      "predict_op3 0.8515625\n",
      "predict_op4 0.8984375\n",
      "predict_op5 0.87109375\n",
      "\n",
      "epoch:  3\n",
      "predict_op1 0.10546875\n",
      "predict_op2 0.5703125\n",
      "predict_op3 0.84765625\n",
      "predict_op4 0.921875\n",
      "predict_op5 0.91796875\n",
      "\n",
      "epoch:  4\n",
      "predict_op1 0.09765625\n",
      "predict_op2 0.58203125\n",
      "predict_op3 0.875\n",
      "predict_op4 0.9375\n",
      "predict_op5 0.91796875\n",
      "\n",
      "epoch:  5\n",
      "predict_op1 0.109375\n",
      "predict_op2 0.578125\n",
      "predict_op3 0.8359375\n",
      "predict_op4 0.91796875\n",
      "predict_op5 0.9140625\n",
      "\n",
      "epoch:  6\n",
      "predict_op1 0.10546875\n",
      "predict_op2 0.578125\n",
      "predict_op3 0.8671875\n",
      "predict_op4 0.93359375\n",
      "predict_op5 0.90625\n",
      "\n",
      "epoch:  7\n",
      "predict_op1 0.11328125\n",
      "predict_op2 0.55859375\n",
      "predict_op3 0.890625\n",
      "predict_op4 0.9296875\n",
      "predict_op5 0.94921875\n",
      "\n",
      "epoch:  8\n",
      "predict_op1 0.1484375\n",
      "predict_op2 0.59765625\n",
      "predict_op3 0.87890625\n",
      "predict_op4 0.95703125\n",
      "predict_op5 0.94140625\n",
      "\n",
      "epoch:  9\n",
      "predict_op1 0.125\n",
      "predict_op2 0.57421875\n",
      "predict_op3 0.890625\n",
      "predict_op4 0.9609375\n",
      "predict_op5 0.953125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 10\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    summary_op = tf.summary.merge_all() # Merge all summaries into a single op\n",
    "    summary_writer = tf.summary.FileWriter(\"rnn_mnist_logs_2_many2many_lstm/\", graph=tf.get_default_graph())\n",
    "    \n",
    "    saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size)):\n",
    "            sess.run([train_op1, train_op2, train_op3, train_op4, train_op5], feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "            # Write logs at every iteration\n",
    "            summary_str = sess.run(summary_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "            summary_writer.add_summary(summary_str, epoch)\n",
    "            \n",
    "        # Save checkpoint\n",
    "        saver.save(sess, \"rnn_mnist_logs_2_many2many_lstm/model-checkpoint\", epoch)\n",
    "\n",
    "        test_indices = np.arange(len(teX))  # Get A Test Batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "\n",
    "        print(\"epoch: \", epoch)\n",
    "        print(\"predict_op1\", np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op1, feed_dict={X: teX[test_indices]})))\n",
    "        print(\"predict_op2\", np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op2, feed_dict={X: teX[test_indices]})))\n",
    "        print(\"predict_op3\", np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op3, feed_dict={X: teX[test_indices]})))\n",
    "        print(\"predict_op4\", np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op4, feed_dict={X: teX[test_indices]})))\n",
    "        print(\"predict_op5\", np.mean(np.argmax(teY[test_indices], axis=1) == sess.run(predict_op5, feed_dict={X: teX[test_indices]})))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "[   0    1    2 ... 9997 9998 9999]\n",
      "(10000,)\n",
      "[5505 9842 9402 ... 3068 8257 3582]\n",
      "(10000,)\n",
      "5505\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(teX.shape)\n",
    "test_indices = np.arange(len(teX))  # Get A Test Batch\n",
    "print(test_indices)\n",
    "print(test_indices.shape)\n",
    "np.random.shuffle(test_indices)\n",
    "print(test_indices)\n",
    "print(test_indices.shape)\n",
    "test_indices = test_indices[0:test_size]\n",
    "print(test_indices[0])\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Interesting cases:\n",
    "8374:\n",
    "Bottom blank\n",
    "predict_op1 0.0\n",
    "predict_op2 1.0\n",
    "predict_op3 0.0\n",
    "predict_op4 0.0\n",
    "predict_op5 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b7f81b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "uncorrupted = []\n",
    "#uncorrupted.append(teX[test_indices[0]])\n",
    "\n",
    "teX_index = test_indices[0]\n",
    "\n",
    "# use any index less than 10,000: 5505(0), 7183(1), 1984(2), 200(3), 7494(4), 2515(5), 2721(6), *2808(7), 4218(8), 104(9)\n",
    "# teX_index = 1984\n",
    "\n",
    "uncorrupted.append(teX[teX_index])\n",
    "uncorrupted = np.array(uncorrupted)\n",
    "print(uncorrupted.shape)\n",
    "\n",
    "print_image(uncorrupted[0], \"Original Image\")\n",
    "print(np.argmax(teY[teX_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ae030a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_image_top0 = copy.deepcopy(teX[teX_index])\n",
    "\n",
    "test_image_top0[0:13] = 0\n",
    "\n",
    "a = []\n",
    "a.append(test_image_top0)\n",
    "a = np.array(a)\n",
    "print(a.shape)\n",
    "\n",
    "print_image(a[0], \"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b7f72ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_bottom0 = copy.deepcopy(teX[teX_index])\n",
    "\n",
    "test_image_bottom0[13:28] = 0\n",
    "\n",
    "b = []\n",
    "b.append(test_image_bottom0)\n",
    "b = np.array(b)\n",
    "print(b.shape)\n",
    "\n",
    "print_image(b[0], \"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from rnn_mnist_logs_2_many2many_lstm\\model-checkpoint-9\n",
      "predict_op1 0.0\n",
      "predict_op2 1.0\n",
      "predict_op3 1.0\n",
      "predict_op4 1.0\n",
      "predict_op5 1.0\n",
      "\n",
      "Top blank\n",
      "predict_op1 0.0\n",
      "predict_op2 0.0\n",
      "predict_op3 0.0\n",
      "predict_op4 0.0\n",
      "predict_op5 0.0\n",
      "\n",
      "Bottom blank\n",
      "predict_op1 0.0\n",
      "predict_op2 1.0\n",
      "predict_op3 1.0\n",
      "predict_op4 1.0\n",
      "predict_op5 0.0\n"
     ]
    }
   ],
   "source": [
    "# graph = tf.Graph()\n",
    "\n",
    "# with graph.as_default():\n",
    "#     saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"rnn_mnist_logs_2_many2many_lstm\"))\n",
    "    \n",
    "    print(\"predict_op1\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op1, feed_dict={X: uncorrupted})))\n",
    "    print(\"predict_op2\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op2, feed_dict={X: uncorrupted})))\n",
    "    print(\"predict_op3\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op3, feed_dict={X: uncorrupted})))\n",
    "    print(\"predict_op4\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op4, feed_dict={X: uncorrupted})))\n",
    "    print(\"predict_op5\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op5, feed_dict={X: uncorrupted})))\n",
    "    print(\"\")\n",
    "    print(\"Top blank\")\n",
    "    print(\"predict_op1\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op1, feed_dict={X: a})))\n",
    "    print(\"predict_op2\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op2, feed_dict={X: a})))\n",
    "    print(\"predict_op3\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op3, feed_dict={X: a})))\n",
    "    print(\"predict_op4\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op4, feed_dict={X: a})))\n",
    "    print(\"predict_op5\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op5, feed_dict={X: a})))\n",
    "    print()\n",
    "    print(\"Bottom blank\")\n",
    "    print(\"predict_op1\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op1, feed_dict={X: b})))\n",
    "    print(\"predict_op2\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op2, feed_dict={X: b})))\n",
    "    print(\"predict_op3\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op3, feed_dict={X: b})))\n",
    "    print(\"predict_op4\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op4, feed_dict={X: b})))\n",
    "    print(\"predict_op5\", np.mean(np.argmax(teY[test_indices[0]], axis=0) == sess.run(predict_op5, feed_dict={X: b})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
