{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary and Save & Restore a Model\n",
    "\n",
    "Save and Restore a model using TensorFlow.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/4_Utils/save_restore_model.ipynb\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/4_Utils/tensorboard_basic.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorboard --logdir=\"summary_save_restore_model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../Datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../Datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Import MINST data\n",
    "mnist = input_data.read_data_sets(\"../../../Datasets/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "training_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "model_path = \"summary_save_restore_model_logs/model.ckpt\"\n",
    "logs_path = 'summary_save_restore_model_logs/'\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name='InputData')\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name='LabelData')\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='Weights1'),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='Weights2'),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='Weights3')\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='Bias1'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='Bias2'),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]), name='Bias3')\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    with tf.name_scope('Model'):\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        # Output layer with linear activation\n",
    "        out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "prediction = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss\n",
    "with tf.name_scope('Loss'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "\n",
    "# Define optimizer\n",
    "with tf.name_scope('Optimizer'):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(logs_path):\n",
    "    shutil.rmtree(logs_path)\n",
    "    os.makedirs(logs_path)\n",
    "else:\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1st session...\n",
      "Epoch: 0001 cost = 158.667582845\n",
      "Accuracy: 0.8658\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-0\n",
      "Epoch: 0002 cost = 40.074491112\n",
      "Accuracy: 0.8992\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-1\n",
      "Epoch: 0003 cost = 25.659467607\n",
      "Accuracy: 0.9095\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-2\n",
      "First Optimization Finished!\n",
      "Final Accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "# Running first session\n",
    "print(\"Starting 1st session...\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    max_accuracy = 0.0\n",
    "    max_accuracy_epoch_no = 0\n",
    "    # Training cycle\n",
    "    for epoch in range(3):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop), cost op (to get loss value)\n",
    "            # and summary nodes - accuracy summary will be stored of training data\n",
    "            _, c, summary = sess.run([train_op, cost, merged_summary_op], feed_dict={x: batch_x, y: batch_y})\n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "        # Accuracy on test data\n",
    "        accuracy_mean = accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Accuracy:\", accuracy_mean)\n",
    "        if accuracy_mean > max_accuracy:\n",
    "            max_accuracy = accuracy_mean\n",
    "            max_accuracy_epoch_no = epoch\n",
    "            # Save model weights to disk only if it performs the best so far\n",
    "            save_path = saver.save(sess, model_path, epoch)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    print(\"First Optimization Finished!\")\n",
    "\n",
    "    print(\"Final Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "#     # Save model weights to disk\n",
    "#     save_path = saver.save(sess, model_path)\n",
    "#     print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 2nd session...\n",
      "INFO:tensorflow:Restoring parameters from summary_save_restore_model_logs/model.ckpt-2\n",
      "Epoch: 0004 cost = 17.719835981\n",
      "Accuracy: 0.9183\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-3\n",
      "Epoch: 0005 cost = 12.896370300\n",
      "Accuracy: 0.925\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-4\n",
      "Epoch: 0006 cost = 9.511559632\n",
      "Accuracy: 0.9274\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-5\n",
      "Epoch: 0007 cost = 7.110977581\n",
      "Accuracy: 0.9328\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-6\n",
      "Epoch: 0008 cost = 5.331307621\n",
      "Accuracy: 0.9323\n",
      "Epoch: 0009 cost = 3.867113543\n",
      "Accuracy: 0.9365\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-8\n",
      "Epoch: 0010 cost = 2.921172225\n",
      "Accuracy: 0.9375\n",
      "Model saved in file: summary_save_restore_model_logs/model.ckpt-9\n",
      "Second Optimization Finished!\n",
      "Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Fill values based on previous training session\n",
    "# max_accuracy = # 0.911\n",
    "# max_accuracy_epoch_no = # 2\n",
    "\n",
    "# last epoch of previous session (the epoch printed above)\n",
    "training_epochs_last = 3\n",
    "\n",
    "# Running a new session\n",
    "print(\"Starting 2nd session...\")\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Restore model weights from previously saved model\n",
    "    #load_path = saver.restore(sess, model_path)\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(logs_path))\n",
    "    \n",
    "    # Resume training\n",
    "    for epoch in range(training_epochs_last, training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop), cost op (to get loss value)\n",
    "            # and summary nodes - accuracy summary will be stored of training data\n",
    "            _, c, summary = sess.run([train_op, cost, merged_summary_op], feed_dict={x: batch_x, y: batch_y})\n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "        \n",
    "        # Accuracy on test data\n",
    "        accuracy_mean = accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Accuracy:\", accuracy_mean)\n",
    "        if accuracy_mean > max_accuracy:\n",
    "            max_accuracy = accuracy_mean\n",
    "            max_accuracy_epoch_no = epoch\n",
    "            # Save model weights to disk only if it performs the best so far\n",
    "            save_path = saver.save(sess, model_path, epoch)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    print(\"Second Optimization Finished!\")\n",
    "\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n",
      "Target:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "INFO:tensorflow:Restoring parameters from summary_save_restore_model_logs/model.ckpt-9\n",
      "Network Output:  [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After training restoring the model and testing it with an input\n",
    "For this you don't need to run training cells (above two cells)\n",
    "Just import TensorFlow and dataset and run the cell where model is defined (where `init` is Initialized)\n",
    "\"\"\"\n",
    "\n",
    "teX, teY = mnist.test.images, mnist.test.labels\n",
    "input_index = 725\n",
    "\n",
    "print(teX.shape)\n",
    "#print(teX[0])\n",
    "input_X = []\n",
    "input_X.append(teX[input_index])\n",
    "\n",
    "print(teY.shape)\n",
    "print(\"Target: \", teY[input_index])\n",
    "input_Y = []\n",
    "input_Y.append(teY[input_index])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(logs_path))\n",
    "    \n",
    "    #print(prediction.eval({x: input_X, y: input_Y}))\n",
    "    \n",
    "    prediction_softmax = tf.nn.softmax(prediction.eval({x: input_X, y: input_Y}))\n",
    "    print(\"Network Output: \", sess.run(prediction_softmax))\n",
    "    \n",
    "    print(\"Accuracy: \", accuracy.eval({x: input_X, y: input_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
