{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://medium.com/@erikhallstrm/using-the-dynamicrnn-api-in-tensorflow-7237aba7f7ea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the DynamicRNN API in TensorFlow (5/7)\n",
    "In the previous guide we built a multi-layered LSTM RNN.\n",
    "In this post we will speed it up by not splitting up our inputs and labels into a list, as done on line 41–42 in our code.\n",
    "You may remove these rows where `inputs_series` and `labels_series` are declared.\n",
    "Next change the `tf.nn.rnn` call on line 47 to the following:\n",
    "```\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(batchX_placeholder, -1), initial_state=rnn_tuple_state)\n",
    "states_series = tf.reshape(states_series, [-1, state_size])\n",
    "```\n",
    "The `dynamic_rnn` function takes the batch inputs of shape `[batch_size, truncated_backprop_length, input_size]`, thus the addition of a single dimension on the end.\n",
    "Output will be the last state of every layer in the network as an `LSTMStateTuple` stored `incurrent_state` as well as a tensor `states_series` with the shape `[batch_size, truncated_backprop_length, state_size]` containing the hidden state of the last layer across all time-steps.\n",
    "\n",
    "![The states are not in lists anymore](pics/1_dh-jHqALFi7rnsEXYKc7Bw.png)\n",
    "\n",
    "The tensor `states_series` is reshaped on the second row in the code sample above to shape `[batch_size*truncated_backprop_length, state_size]`, we will see the reason for this shortly.\n",
    "You may read more about `dynamic_rnn` in the documentation.\n",
    "\n",
    "Now input this two lines below the reshaping of the `states_series`.\n",
    "```\n",
    "logits = tf.matmul(states_series, W2) + b2 #Broadcasted addition\n",
    "labels = tf.reshape(batchY_placeholder, [-1])\n",
    "```\n",
    "Notice that we are now only working with tensors, Python lists were a thing of the past.\n",
    "The calculation of the logits and the labels are visualized below, notice the `state_series` variable that was reshaped earlier.\n",
    "In TensorFlow reshaping is done in C-like index order.\n",
    "It means that we read from the source tensor and “write” to the destination tensor with the last axis index changing fastest, and the first axis index changing slowest.\n",
    "The result of the reshaping will be as visualized in the figure below, where similar colors denote the same time-step, and the vertical grouped spacing of elements denote different batches.\n",
    "\n",
    "![Visualization of the calculations, similar color denote same time-step, vertical spacing denote new batch.](pics\\1_mpS2qMofKbmr0nU1wm5tjQ.png)\n",
    "\n",
    "Let’s go trough all the tensors in the figure above, first let’s start with the sizes.\n",
    "We have that `batch_size=3`, `state_size=3`, `num_classes=2` and `truncated_backprop_length=3`.\n",
    "The tensor `states_series` have shape `[batch_size*truncated_backprop_length, state_size]`, labels have shape `[batch_size*truncated_backprop_length]`, logits have shape `[batch_size*truncated_backprop_length, num_classes]`, W2 have shape `[state_size, num_classes]` and b2 have shape `[1, num_classes]`.\n",
    "It can be a bit tricky to keep track of all the tensors, but drawing and visualizing with colors definitely helps.\n",
    "\n",
    "Next calculate the predictions for the visualization:\n",
    "```\n",
    "logits_series = tf.unpack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)\n",
    "predictions_series = [tf.nn.softmax(logit) for logit in logits_list]\n",
    "```\n",
    "Here we actually split the tensors into lists again.\n",
    "This is perhaps not the best way to do it, but it’s quick and dirty, and the plot function is already expecting a list.\n",
    "\n",
    "The `sparse_softmax_cross_entropy_with_logits` can take the shape of our tensors! Modify the losses calculation to this.\n",
    "`losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)`\n",
    "\n",
    "As we can read in the API the logits must have the shape `[batch_size, num_classes]` and labels must have the shape `[batch_size]`.\n",
    "But now we are treating all time-steps as elements in our batch, so it will work out as we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc1b0d7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.6936618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc31cbbe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.68458617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fced1287f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.58839816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc173a2f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.5865731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17ec9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.39865032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17ec9748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.11427391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a7b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.007525677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a8a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.35627097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf4d23e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.0044049737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc16fe0c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.0026294002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc173a96a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.0021609715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc16fa9b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.0015197342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf4d24eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0013083183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc16ffd7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0011340654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc16ff47b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.48654053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fced0d5e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.0012466771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcecfbaac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.0010779157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a06160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.0009491885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc1708a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.00074255577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcecfc5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0007440042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fced0473c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0006668937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a3a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.4725654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf4d2d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.00053387677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf5fbc4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.0005258962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcecf81e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.0004296421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a66f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.0004770064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a51a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0005123299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fced0c1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.00045100227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc1704cf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.40116233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a062e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.00036340117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf5ff4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.00036891134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcf600e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.00038968885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc31be7320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.00034935639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17aa1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.00026111535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17086d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.00033757355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc17a1f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 5#100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_layers = 3\n",
    "\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])\n",
    "\n",
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "     for idx in range(num_layers)]\n",
    ")\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# Forward passes\n",
    "#cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
    "#cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "\n",
    "stacked_rnn = []\n",
    "for _ in range(num_layers):\n",
    "    stacked_rnn.append(tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True))\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(stacked_rnn, state_is_tuple=True)\n",
    "\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(batchX_placeholder, -1), initial_state=rnn_tuple_state)\n",
    "states_series = tf.reshape(states_series, [-1, state_size])\n",
    "\n",
    "logits = tf.matmul(states_series, W2) + b2 #Broadcasted addition\n",
    "labels = tf.reshape(batchY_placeholder, [-1])\n",
    "\n",
    "logits_series = tf.unstack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)\n",
    "predictions_series = [tf.nn.softmax(logit) for logit in logits_series]\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "\n",
    "        _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    init_state: _current_state\n",
    "                })\n",
    "\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
