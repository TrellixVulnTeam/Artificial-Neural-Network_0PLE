{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://medium.com/@erikhallstrm/using-the-tensorflow-lstm-api-3-7-5f2b97ca6b73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the LSTM API in TensorFlow (3/7)\n",
    "In the previous post we modified our to code to use the TensorFlow native RNN API.\n",
    "Now we will go about to build a modification of a RNN that called a “Recurrent Neural Network with Long short-term memory” or RNN-LSTM.\n",
    "This architecture was pioneered by Jürgen Schmidhuber among others.\n",
    "One problem with the RNN when using long time-dependencies (`truncated_backprop_length` is large) is the “vanishing gradient problem”: http://neuralnetworksanddeeplearning.com/chap5.html\n",
    "One way to counter this is using a state that is “protected” and “selective”.\n",
    "The RNN-LSTM remembers, forgets and chooses what to pass on and output depending on the current state and input.\n",
    "\n",
    "Since this primarily is a practical tutorial I won’t go into more detail about the theory, I recommend reading this article again, continue with the “Modern RNN architectures”: https://arxiv.org/pdf/1506.00019.pdf\n",
    "After you have done that read and look at the figures on this page.\n",
    "Notice that the last mentioned resource are using vector concatenation in their calculations.\n",
    "\n",
    "In the previous article we didn’t have to allocate the internal weight matrix and bias, that was done by TensorFlow automatically “under the hood”.\n",
    "A LSTM RNN has many more “moving parts”, but by using the native API it will also be very simple.\n",
    "\n",
    "# Different state\n",
    "A LSTM have a “cell state” and a “hidden state”, to account for this you need to remove `_current_state` on line 79 in the previous script and replace it with this:\n",
    "```\n",
    "_current_cell_state = np.zeros((batch_size, state_size))\n",
    "_current_hidden_state = np.zeros((batch_size, state_size))\n",
    "```\n",
    "\n",
    "TensorFlow uses a data structure called `LSTMStateTuple` internally for its LSTMs, where the first element in the tuple is the cell state, and the second is the hidden state.\n",
    "So you need to change line 28 where the `init_state` is placeholders are declared to these lines:\n",
    "```\n",
    "cell_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "```\n",
    "Changing the forward pass is now straight forward, you just change the function call to create a LSTM and supply the initial state-tuple on line 38–39.\n",
    "```\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, state_is_tuple=True)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)\n",
    "```\n",
    "<u>The `states_series` will be a list of hidden states as tensors, and `current_state` will be a LSTMStateTuple which shows both the hidden- and the cell state on the last time-step as shown below:</u>\n",
    "\n",
    "![Outputs of the previous states and the last LSTMStateTuple](pics/1_74HCrPbTjstECrQXZzJtDQ.png)\n",
    "\n",
    "So the `current_state` returns the cell- and hidden state in a tuple.\n",
    "They should be separated after calculation and supplied to the placeholders in the run-function on line 90.\n",
    "```\n",
    "_total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "    [total_loss, train_step, current_state, predictions_series],\n",
    "    feed_dict={\n",
    "        batchX_placeholder: batchX,\n",
    "        batchY_placeholder: batchY,\n",
    "        cell_state: _current_cell_state,\n",
    "        hidden_state: _current_hidden_state\n",
    "\n",
    "    })\n",
    "\n",
    "_current_cell_state, _current_hidden_state = _current_state\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_state:  Tensor(\"Placeholder_2:0\", shape=(5, 4), dtype=float32)\n",
      "hidden_state:  Tensor(\"Placeholder_3:0\", shape=(5, 4), dtype=float32)\n",
      "init_state:  LSTMStateTuple(c=<tf.Tensor 'Placeholder_2:0' shape=(5, 4) dtype=float32>, h=<tf.Tensor 'Placeholder_3:0' shape=(5, 4) dtype=float32>)\n",
      "states_series:  [<tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_2:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_5:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_8:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_11:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_14:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_17:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_20:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_23:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_26:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_29:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_32:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_35:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_38:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_41:0' shape=(5, 4) dtype=float32>, <tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_44:0' shape=(5, 4) dtype=float32>]\n",
      "current_state:  LSTMStateTuple(c=<tf.Tensor 'rnn/rnn/basic_lstm_cell/add_29:0' shape=(5, 4) dtype=float32>, h=<tf.Tensor 'rnn/rnn/basic_lstm_cell/mul_44:0' shape=(5, 4) dtype=float32>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb78189710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.6847398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb781e2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.6903279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb8003c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.5376254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebecbdbef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.3745834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebefe13860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.26797488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf1134668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.2107292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf1174dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.015902335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebea596400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.6586295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01a90da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.006981566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb755630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.004477961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb77d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.0035909899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfa2519b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.0024970921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec0422fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0022026335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb8b0c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0024576653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf1150dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.8107532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01b04160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.00191311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb686e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.0014569368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfa240080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.0012985464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb8fc7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.0015577151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb8a22b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0010756091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec041d7438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0009408433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf11195c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.7937352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfe904550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.0010361391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebefe34e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.001043925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfe9214e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.000841864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebecbd2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.00083522894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfa2f1438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.0007012048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf11816d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0006273109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebf115f048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.62024146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebfa240198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.000759213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01b66908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Batch loss 0.0007472509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01b06e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Batch loss 0.00067188643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01a1bf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Batch loss 0.00056284555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb5dc128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Batch loss 0.00048423384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebeb7f2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Batch loss 0.0005423832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec01bea470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 5#100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "cell_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "print(\"cell_state: \", cell_state)\n",
    "print(\"hidden_state: \", hidden_state)\n",
    "print(\"init_state: \", init_state)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# Unpack columns\n",
    "inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "\n",
    "# Forward passes\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, state_is_tuple=True)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)\n",
    "\n",
    "print(\"states_series: \", states_series)\n",
    "print(\"current_state: \", current_state)\n",
    "\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_cell_state = np.zeros((batch_size, state_size))\n",
    "        _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    cell_state: _current_cell_state,\n",
    "                    hidden_state: _current_hidden_state\n",
    "\n",
    "                })\n",
    "\n",
    "            _current_cell_state, _current_hidden_state = _current_state\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
